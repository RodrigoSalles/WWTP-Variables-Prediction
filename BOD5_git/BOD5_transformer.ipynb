{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144b30e2",
   "metadata": {},
   "source": [
    "# Prediction of Key Variables in Wastewater Treatment Plants Using Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1cbe44",
   "metadata": {},
   "source": [
    "## Case Studies - Transformer Algorithm\n",
    "\n",
    "## Notebook developed for WCCI paper case study: <p style=\"color:blue\"> Biological Oxygen Demand (BOD5).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c15f6d",
   "metadata": {},
   "source": [
    "## Data source: Benchmark Simulation Model No 2 - BSM2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4634ae5",
   "metadata": {},
   "source": [
    "## Objective: \n",
    "Predict BOD5 value at the entrance of aerobic tank number 3\n",
    "\n",
    "As the objective is to predict the BOD value at the entrance of the aerobic tank, the data will be collected between units (tanks) 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c89d3",
   "metadata": {},
   "source": [
    "## Initial Exploratory Data Analysis\n",
    "\n",
    "The initial exploratory analysis was performed on the main notebook for the case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ceae177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "print('Tensorflow version: {}'.format(tf.__version__))\n",
    "plt.style.use('seaborn')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3c21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load datasets\n",
    "df_entrada = pd.read_csv('datasets/dado3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcce1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete 5 dummy variables\n",
    "df_entrada.drop([\"d1\", \"d2\",\"d3\",\"dp1\",\"dp2\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617970d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula to approximate the value of BOD5\n",
    "df_entrada['CBO5'] = 0.25*(df_entrada['S_S'] + df_entrada['X_S'] + (1-0.08)*(df_entrada['X_b,h'] + df_entrada['X_b,a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dcee56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_entrada.filter(['X_b,h', 'X_p', 'S_0','CBO5', 'S_ND'], axis=1)\n",
    "\n",
    "df = df1[0:17280] # 180 days for training and testing\n",
    "val_data = df1[34744:36001] # 10 days (holdout sample) for final test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41acf73",
   "metadata": {},
   "source": [
    "## Algorithms: Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16c04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 96\n",
    "d_k = 256\n",
    "d_v = 256\n",
    "n_heads = 12\n",
    "ff_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae512cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scalerT = scaler.fit(df)\n",
    "train_data = scalerT.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece82d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train, y_train = [], []\n",
    "for i in range(seq_len, len(train_data)):\n",
    "    X_train.append(train_data[i-seq_len:i]) \n",
    "    y_train.append(train_data[:, 3][i])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376c7673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Validation data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scalerV = scaler.fit(val_data)\n",
    "val_data = scalerV.transform(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b2f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation data\n",
    "X_val, y_val = [], []\n",
    "for i in range(seq_len, len(val_data)):\n",
    "    X_val.append(val_data[i-seq_len:i])\n",
    "    y_val.append(val_data[:, 3][i])\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fdd9b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (17184, 96, 5) (17184,)\n",
      "Validation set shape (1161, 96, 5) (1161,)\n"
     ]
    }
   ],
   "source": [
    "print('Training set shape', X_train.shape, y_train.shape)\n",
    "print('Validation set shape', X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859f6833",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Time2Vector(Layer):\n",
    "    def __init__(self, seq_len, **kwargs):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        '''Initialize weights and biases with shape (batch, seq_len)'''\n",
    "        self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        '''Calculate linear and periodic time features'''\n",
    "        x = tf.math.reduce_mean(x[:,:,:4], axis=-1) \n",
    "        time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
    "        time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "\n",
    "        time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "        time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "        return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
    "   \n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'seq_len': self.seq_len})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fea0f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttention(Layer):\n",
    "    def __init__(self, d_k, d_v):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.query = Dense(self.d_k, \n",
    "                           input_shape=input_shape, \n",
    "                           kernel_initializer='glorot_uniform', \n",
    "                           bias_initializer='glorot_uniform')\n",
    "\n",
    "        self.key = Dense(self.d_k, \n",
    "                         input_shape=input_shape, \n",
    "                         kernel_initializer='glorot_uniform', \n",
    "                         bias_initializer='glorot_uniform')\n",
    "\n",
    "        self.value = Dense(self.d_v, \n",
    "                           input_shape=input_shape, \n",
    "                           kernel_initializer='glorot_uniform', \n",
    "                           bias_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "\n",
    "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "\n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = tf.matmul(attn_weights, v)\n",
    "        return attn_out    \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "class MultiAttention(Layer):\n",
    "    def __init__(self, d_k, d_v, n_heads):\n",
    "        super(MultiAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.attn_heads = list()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        for n in range(self.n_heads):\n",
    "            self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
    "\n",
    "        # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \n",
    "        self.linear = Dense(input_shape[0][-1], \n",
    "                            input_shape=input_shape, \n",
    "                            kernel_initializer='glorot_uniform', \n",
    "                            bias_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "        concat_attn = tf.concat(attn, axis=-1)\n",
    "        multi_linear = self.linear(concat_attn)\n",
    "        return multi_linear   \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.attn_heads = list()\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "        self.attn_dropout = Dropout(self.dropout_rate)\n",
    "        self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "        # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 \n",
    "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
    "        self.ff_dropout = Dropout(self.dropout_rate)\n",
    "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
    "  \n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        attn_layer = self.attn_multi(inputs)\n",
    "        attn_layer = self.attn_dropout(attn_layer)\n",
    "        attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer \n",
    "\n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'d_k': self.d_k,\n",
    "                       'd_v': self.d_v,\n",
    "                       'n_heads': self.n_heads,\n",
    "                       'ff_dim': self.ff_dim,\n",
    "                       'attn_heads': self.attn_heads,\n",
    "                       'dropout_rate': self.dropout_rate})\n",
    "        return config          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a7fc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 96, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time2_vector_1 (Time2Vector)    (None, 96, 2)        384         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 7)        0           input_2[0][0]                    \n",
      "                                                                 time2_vector_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_3 (Transfor (None, 96, 7)        99114       concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_4 (Transfor (None, 96, 7)        99114       transformer_encoder_3[0][0]      \n",
      "                                                                 transformer_encoder_3[0][0]      \n",
      "                                                                 transformer_encoder_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder_5 (Transfor (None, 96, 7)        99114       transformer_encoder_4[0][0]      \n",
      "                                                                 transformer_encoder_4[0][0]      \n",
      "                                                                 transformer_encoder_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 96)           0           transformer_encoder_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 96)           0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           6208        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 303,999\n",
      "Trainable params: 303,999\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "537/537 [==============================] - 246s 440ms/step - loss: 0.1994 - mae: 0.3039 - mape: 151.7782 - val_loss: 0.0982 - val_mae: 0.2406 - val_mape: 96.8014\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09823, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 2/40\n",
      "537/537 [==============================] - 232s 432ms/step - loss: 0.0410 - mae: 0.1553 - mape: 102.1041 - val_loss: 0.0559 - val_mae: 0.1739 - val_mape: 93.0526\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09823 to 0.05594, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 3/40\n",
      "537/537 [==============================] - 235s 438ms/step - loss: 0.0311 - mae: 0.1353 - mape: 86.9162 - val_loss: 0.0501 - val_mae: 0.1607 - val_mape: 60.5223\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05594 to 0.05012, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 4/40\n",
      "537/537 [==============================] - 238s 443ms/step - loss: 0.0288 - mae: 0.1299 - mape: 70.9629 - val_loss: 0.0393 - val_mae: 0.1536 - val_mape: 61.8681\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05012 to 0.03926, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 5/40\n",
      "537/537 [==============================] - 363s 676ms/step - loss: 0.0239 - mae: 0.1185 - mape: 75.6314 - val_loss: 0.0342 - val_mae: 0.1358 - val_mape: 82.9972\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03926 to 0.03417, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 6/40\n",
      "537/537 [==============================] - 438s 815ms/step - loss: 0.0215 - mae: 0.1124 - mape: 61.4444 - val_loss: 0.0311 - val_mae: 0.1315 - val_mape: 56.2337\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03417 to 0.03106, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 7/40\n",
      "537/537 [==============================] - 450s 839ms/step - loss: 0.0197 - mae: 0.1080 - mape: 64.5438 - val_loss: 0.0342 - val_mae: 0.1406 - val_mape: 58.3752\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03106\n",
      "Epoch 8/40\n",
      "537/537 [==============================] - 590s 1s/step - loss: 0.0186 - mae: 0.1044 - mape: 64.0157 - val_loss: 0.0276 - val_mae: 0.1246 - val_mape: 52.7626\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03106 to 0.02756, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 9/40\n",
      "537/537 [==============================] - 603s 1s/step - loss: 0.0171 - mae: 0.1005 - mape: 57.2513 - val_loss: 0.0337 - val_mae: 0.1411 - val_mape: 57.4046\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02756\n",
      "Epoch 10/40\n",
      "537/537 [==============================] - 607s 1s/step - loss: 0.0168 - mae: 0.0986 - mape: 51.5537 - val_loss: 0.0318 - val_mae: 0.1354 - val_mape: 71.6556\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02756\n",
      "Epoch 11/40\n",
      "537/537 [==============================] - 609s 1s/step - loss: 0.0155 - mae: 0.0948 - mape: 51.2818 - val_loss: 0.0253 - val_mae: 0.1210 - val_mape: 54.6581\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02756 to 0.02531, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 12/40\n",
      "537/537 [==============================] - 608s 1s/step - loss: 0.0158 - mae: 0.0952 - mape: 51.6252 - val_loss: 0.0260 - val_mae: 0.1231 - val_mape: 75.5843\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02531\n",
      "Epoch 13/40\n",
      "537/537 [==============================] - 609s 1s/step - loss: 0.0138 - mae: 0.0895 - mape: 50.4848 - val_loss: 0.0265 - val_mae: 0.1258 - val_mape: 48.6780\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02531\n",
      "Epoch 14/40\n",
      "537/537 [==============================] - 608s 1s/step - loss: 0.0136 - mae: 0.0893 - mape: 48.3153 - val_loss: 0.0231 - val_mae: 0.1177 - val_mape: 64.2546\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02531 to 0.02309, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 15/40\n",
      "537/537 [==============================] - 607s 1s/step - loss: 0.0140 - mae: 0.0901 - mape: 50.0464 - val_loss: 0.0256 - val_mae: 0.1224 - val_mape: 64.5660\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02309\n",
      "Epoch 16/40\n",
      "537/537 [==============================] - 606s 1s/step - loss: 0.0130 - mae: 0.0870 - mape: 49.7471 - val_loss: 0.0274 - val_mae: 0.1328 - val_mape: 58.1935\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02309\n",
      "Epoch 17/40\n",
      "537/537 [==============================] - 611s 1s/step - loss: 0.0129 - mae: 0.0860 - mape: 44.2899 - val_loss: 0.0246 - val_mae: 0.1209 - val_mape: 67.2944\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02309\n",
      "Epoch 18/40\n",
      "537/537 [==============================] - 606s 1s/step - loss: 0.0128 - mae: 0.0854 - mape: 45.7483 - val_loss: 0.0298 - val_mae: 0.1350 - val_mape: 64.3996\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02309\n",
      "Epoch 19/40\n",
      "537/537 [==============================] - 612s 1s/step - loss: 0.0122 - mae: 0.0833 - mape: 43.0572 - val_loss: 0.0214 - val_mae: 0.1139 - val_mape: 60.2180\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02309 to 0.02138, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 20/40\n",
      "537/537 [==============================] - 609s 1s/step - loss: 0.0117 - mae: 0.0819 - mape: 45.3479 - val_loss: 0.0204 - val_mae: 0.1117 - val_mape: 46.5722\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02138 to 0.02042, saving model to Transformer_BOD5.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40\n",
      "537/537 [==============================] - 609s 1s/step - loss: 0.0121 - mae: 0.0830 - mape: 42.9134 - val_loss: 0.0212 - val_mae: 0.1143 - val_mape: 45.9497\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02042\n",
      "Epoch 22/40\n",
      "537/537 [==============================] - 608s 1s/step - loss: 0.0113 - mae: 0.0801 - mape: 41.9240 - val_loss: 0.0245 - val_mae: 0.1134 - val_mape: 50.5127\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02042\n",
      "Epoch 23/40\n",
      "537/537 [==============================] - 608s 1s/step - loss: 0.0112 - mae: 0.0798 - mape: 43.0627 - val_loss: 0.0193 - val_mae: 0.1063 - val_mape: 52.4097\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02042 to 0.01930, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 24/40\n",
      "537/537 [==============================] - 604s 1s/step - loss: 0.0115 - mae: 0.0802 - mape: 42.6217 - val_loss: 0.0284 - val_mae: 0.1195 - val_mape: 58.9134\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01930\n",
      "Epoch 25/40\n",
      "537/537 [==============================] - 607s 1s/step - loss: 0.0107 - mae: 0.0772 - mape: 40.4312 - val_loss: 0.0183 - val_mae: 0.1044 - val_mape: 64.5539\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01930 to 0.01834, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 26/40\n",
      "537/537 [==============================] - 609s 1s/step - loss: 0.0106 - mae: 0.0770 - mape: 40.3613 - val_loss: 0.0185 - val_mae: 0.1038 - val_mape: 77.2870\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01834\n",
      "Epoch 27/40\n",
      "537/537 [==============================] - 612s 1s/step - loss: 0.0110 - mae: 0.0782 - mape: 39.1311 - val_loss: 0.0197 - val_mae: 0.1053 - val_mape: 54.4140\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01834\n",
      "Epoch 28/40\n",
      "537/537 [==============================] - 605s 1s/step - loss: 0.0104 - mae: 0.0758 - mape: 36.5191 - val_loss: 0.0165 - val_mae: 0.0994 - val_mape: 63.3634\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01834 to 0.01652, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 29/40\n",
      "537/537 [==============================] - 608s 1s/step - loss: 0.0106 - mae: 0.0766 - mape: 36.2186 - val_loss: 0.0137 - val_mae: 0.0889 - val_mape: 51.9319\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01652 to 0.01366, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 30/40\n",
      "537/537 [==============================] - 606s 1s/step - loss: 0.0102 - mae: 0.0751 - mape: 37.0125 - val_loss: 0.0162 - val_mae: 0.0974 - val_mape: 66.1642\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01366\n",
      "Epoch 31/40\n",
      "537/537 [==============================] - 603s 1s/step - loss: 0.0100 - mae: 0.0740 - mape: 34.0582 - val_loss: 0.0139 - val_mae: 0.0922 - val_mape: 72.9452\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01366\n",
      "Epoch 32/40\n",
      "537/537 [==============================] - 603s 1s/step - loss: 0.0100 - mae: 0.0744 - mape: 39.2474 - val_loss: 0.0147 - val_mae: 0.0915 - val_mape: 69.0447\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01366\n",
      "Epoch 33/40\n",
      "537/537 [==============================] - 607s 1s/step - loss: 0.0098 - mae: 0.0732 - mape: 34.8933 - val_loss: 0.0130 - val_mae: 0.0875 - val_mape: 62.1454\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01366 to 0.01302, saving model to Transformer_BOD5.hdf5\n",
      "Epoch 34/40\n",
      "537/537 [==============================] - 606s 1s/step - loss: 0.0098 - mae: 0.0739 - mape: 36.0752 - val_loss: 0.0162 - val_mae: 0.0980 - val_mape: 76.1010\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01302\n",
      "Epoch 35/40\n",
      "537/537 [==============================] - 607s 1s/step - loss: 0.0095 - mae: 0.0726 - mape: 37.3581 - val_loss: 0.0169 - val_mae: 0.1017 - val_mape: 65.5548\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01302\n",
      "Epoch 36/40\n",
      "537/537 [==============================] - 603s 1s/step - loss: 0.0095 - mae: 0.0716 - mape: 34.9079 - val_loss: 0.0152 - val_mae: 0.0967 - val_mape: 56.2693\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01302\n",
      "Epoch 37/40\n",
      "537/537 [==============================] - 603s 1s/step - loss: 0.0091 - mae: 0.0710 - mape: 35.6757 - val_loss: 0.0140 - val_mae: 0.0882 - val_mape: 44.9374\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01302\n",
      "Epoch 38/40\n",
      "537/537 [==============================] - 601s 1s/step - loss: 0.0094 - mae: 0.0710 - mape: 35.0373 - val_loss: 0.0134 - val_mae: 0.0911 - val_mape: 66.3014\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01302\n",
      "Epoch 39/40\n",
      "537/537 [==============================] - 607s 1s/step - loss: 0.0098 - mae: 0.0732 - mape: 35.9795 - val_loss: 0.0185 - val_mae: 0.1070 - val_mape: 71.2652\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01302\n",
      "Epoch 40/40\n",
      "537/537 [==============================] - 607s 1s/step - loss: 0.0091 - mae: 0.0695 - mape: 32.1789 - val_loss: 0.0212 - val_mae: 0.1149 - val_mape: 74.5493\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01302\n"
     ]
    }
   ],
   "source": [
    "# If the algorithm has already been created and trained, you don't need to run this part.\n",
    "\n",
    "def create_model():\n",
    "    # Initialize time and transformer layers\n",
    "    time_embedding = Time2Vector(seq_len)\n",
    "    attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "    attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "    # Construct model\n",
    "    in_seq = Input(shape=(seq_len, 5))\n",
    "    x = time_embedding(in_seq)\n",
    "    x = Concatenate(axis=-1)([in_seq, x])\n",
    "    x = attn_layer1((x, x, x))\n",
    "    x = attn_layer2((x, x, x))\n",
    "    x = attn_layer3((x, x, x))\n",
    "    x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    out = Dense(1, activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=in_seq, outputs=out)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mape'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint('Transformer_BOD5.hdf5', \n",
    "                                              monitor='val_loss', \n",
    "                                              save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=40, \n",
    "                    callbacks=[callback],\n",
    "                    validation_data=(X_val, y_val))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0d14cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('modelos/Transformer_BOD5.hdf5',\n",
    "                                   custom_objects={'Time2Vector': Time2Vector, \n",
    "                                                   'SingleAttention': SingleAttention,\n",
    "                                                   'MultiAttention': MultiAttention,\n",
    "                                                   'TransformerEncoder': TransformerEncoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af0a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate predictions and metrics'''\n",
    "\n",
    "#Calculate predication for training, validation and test data\n",
    "train_pred = model.predict(X_val)\n",
    "\n",
    "#X_val, y_val\n",
    "#Print evaluation metrics for all datasets\n",
    "train_eval = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print(' ')\n",
    "print('Evaluation metrics')\n",
    "print('Training Data - Loss: {:.4f}, MAE: {:.4f}, MAPE: {:.4f}'.format(train_eval[0], train_eval[1], train_eval[2]))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "'''Display results'''\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Transformer\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot training data results\n",
    "ax11 = fig.add_subplot(311)\n",
    "ax11.plot(val_data[:, 3], label='BOD5_real')\n",
    "ax11.plot(np.arange(seq_len, train_pred.shape[0]+seq_len), train_pred, linewidth=1, label='BOD5_pred')\n",
    "ax11.set_title(\"BOD5_target\", fontsize=18)\n",
    "ax11.set_xlabel('BOD5_target')\n",
    "ax11.set_ylabel('BOD5_target')\n",
    "ax11.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbe7d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction with trained model\n",
    "previsao_trans = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f949b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy scaler dimension to do inverse normalization\n",
    "prediction_copies = np.repeat(previsao_trans , val_data.shape[1], axis=-1)\n",
    "previstoT = scalerV.inverse_transform(prediction_copies)[:,3] # valor previsto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49cd15f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previstoT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90334d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with original format\n",
    "df1 = df_entrada.filter(['X_b,h', 'X_p', 'S_0','CBO5', 'S_ND'], axis=1)\n",
    "\n",
    "\n",
    "df = df1[0:17280] \n",
    "val_data = df1[34744:36001] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f85d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with actual and forecast values\n",
    "df2 = val_data.CBO5\n",
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccef5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[96:1257]\n",
    "df3 = df3.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c3d3871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b39d74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3[96:1161]\n",
    "df4 = df4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "823415e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevT = previstoT[96:1161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b8f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOD5 graph\n",
    "plt.figure(figsize = (15, 6))\n",
    "plt.plot(df4) \n",
    "plt.plot(prevT) # em verde \n",
    "plt.title('Transformer', family='Arial', fontsize=14)\n",
    "plt.xlabel('Samples(15 minutos)')\n",
    "plt.ylabel('BOD5 value')\n",
    "plt.legend(['Ral value', 'Predicted value'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e67b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export forecast values\n",
    "pd.DataFrame(prevT).to_csv('previsao_CBO5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
